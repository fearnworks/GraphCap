==============================
Caption Perspective Nodes
==============================

Overview
========
Caption Perspective Nodes are a specialized category within graphcap that execute various image captioning perspectives. These nodes leverage advanced vision and language models to extract structured analyses from images. They are a core part of the ``graphcap.caption`` module, enabling both artistic analysis and structured graph-based analysis.

Major Node Types
================

1. **PerspectiveNode**
   
   - **Purpose:**  
     Executes a selected caption perspective on a list of image paths using configurable model parameters and a chosen AI provider.
   
   - **Features:**  
     - Processes image paths using specific perspectives (e.g., `"art"` for artistic analysis or `"graph"` for structured scene analysis).
     - Supports asynchronous batch processing.
     - Returns structured analysis data (e.g., textual reports, HTML snippets, or diagram data).
   
   - **Usage Example:**
   
     .. code-block:: python
     
         from graphcap.caption.nodes.perspective import PerspectiveNode
         
         # Initialize the art perspective node
         node = PerspectiveNode(id="art_analysis")
         results = await node.execute(
             image_paths=["/path/to/image1.jpg", "/path/to/image2.jpg"],
             perspective_type="art",
             provider_name="gemini",
             model_params={
                 "max_tokens": 4096,
                 "temperature": 0.8,
                 "top_p": 0.9,
                 "max_concurrent": 2
             }
         )
         print(results)

2. **PerspectiveOutputNode**
   
   - **Purpose:**  
     Organizes and stores the outputs generated by a PerspectiveNode. It handles output formatting, creates directory structures, optionally copies source images, and stores logs.
   
   - **Features:**  
     - Saves output data in multiple formats (e.g., HTML reports, formal text files, or network diagrams).
     - Organizes results by perspective type in batch-specific directories.
     - Optionally stores process logs and copies images to an output folder.
   
   - **Usage Example:**
   
     .. code-block:: python
     
         from graphcap.caption.nodes.output import PerspectiveOutputNode
         
         output_node = PerspectiveOutputNode(id="save_art_outputs")
         output = await output_node.execute(
             perspective_results=results,  # Data output from PerspectiveNode
             output={
                 "directory": "/workspace/.local/output/dags/smoke",
                 "formats": ["html", "formal"],
                 "store_logs": True,
                 "copy_images": True
             },
             batch_timestamp="20231005_143000",
             perspective_type="art"
         )
         print(output)

Workflow Integration
====================
In practice, Caption Perspective Nodes are seamlessly integrated into batch workflows. For example, a typical workflow may include the following steps:

- **Image Loader Node:** Uses ImageSamplingNode to sample images from a dataset.
- **Perspective Processing Nodes:** Utilize PerspectiveNode to perform both artistic (`"art"`) and graph (`"graph"`) analyses.
- **Output Nodes:** Apply PerspectiveOutputNode (e.g., nodes named "save_art_outputs" or "save_graph_outputs") to format and save analysis results.
- **Dataset Export:** Optionally, an additional node (such as a DatasetExportNode) aggregates results for final dataset creation and upload.

Example Batch Configs:
Refer to our workflow configuration files for concrete examples:

- ``config/workflows/smoke_test_image_load.json`` demonstrates a smoke test including both art and graph perspective analyses.
- ``config/workflows/image_analysis.json`` details a full workflow for art analysis, integrating sampling, perspective processing, and output management.

Conclusion
==========
Caption Perspective Nodes extend GraphCap's capabilities by offering flexible, configurable image analysis. Their integration into batch workflows allows for automated processing, structured output generation, and seamless export of results, thereby supporting advanced image captioning strategies. 